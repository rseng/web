---
parser: "github"
uid: "github/ropensci/robotstxt"
url: "https://api.github.com/repos/ropensci/robotstxt"
timestamp: "2022-01-27 10:11:35.133996"
description: "robots.txt file parsing and checking for R"
avatar: "https://avatars.githubusercontent.com/u/1200269?v=4"
repo_url: "https://github.com/ropensci/robotstxt"
name: "robotstxt"
full_name: "ropensci/robotstxt"
html_url: "https://github.com/ropensci/robotstxt"
created_at: "2015-12-01T15:51:07Z"
updated_at: "2021-12-13T17:22:46Z"
clone_url: "https://github.com/ropensci/robotstxt.git"
homepage: "https://docs.ropensci.org/robotstxt"
size: 2700
stargazers_count: 56
watchers_count: 56
language: "R"
license: {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}
owner: {"html_url": "https://github.com/ropensci", "avatar_url": "https://avatars.githubusercontent.com/u/1200269?v=4", "login": "ropensci", "type": "Organization"}
topics: ["robotstxt", "crawler", "webscraping", "spider", "scraper", "r", "rstats", "r-package", "peer-reviewed", "http-tools"]
date: "2023-04-01 14:18:50.956354"
---

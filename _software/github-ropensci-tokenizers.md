---
parser: "github"
uid: "github/ropensci/tokenizers"
url: "https://api.github.com/repos/ropensci/tokenizers"
timestamp: "2022-01-27 10:11:35.144272"
description: "Fast, Consistent Tokenization of Natural Language Text"
avatar: "https://avatars.githubusercontent.com/u/1200269?v=4"
repo_url: "https://github.com/ropensci/tokenizers"
name: "tokenizers"
full_name: "ropensci/tokenizers"
html_url: "https://github.com/ropensci/tokenizers"
created_at: "2016-03-25T04:16:33Z"
updated_at: "2022-01-15T14:45:23Z"
clone_url: "https://github.com/ropensci/tokenizers.git"
homepage: "https://docs.ropensci.org/tokenizers"
size: 1278
stargazers_count: 167
watchers_count: 167
language: "R"
open_issues_count: 3
license: {"key": "other", "name": "Other", "spdx_id": "NOASSERTION", "url": null, "node_id": "MDc6TGljZW5zZTA="}
owner: {"html_url": "https://github.com/ropensci", "avatar_url": "https://avatars.githubusercontent.com/u/1200269?v=4", "login": "ropensci", "type": "Organization"}
topics: ["text-mining", "tokenizer", "rstats", "nlp", "r", "r-package", "peer-reviewed", "scalereprod"]
date: "2023-05-20 14:19:56.725328"
---
